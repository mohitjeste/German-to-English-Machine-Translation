{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, Dataset\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the spacy tokenizers\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load a document into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "\tlines = doc.strip().split('\\n')\n",
    "\tpairs = [line.split('\\t') for line in  lines]\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor pair in lines:\n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "\t\t\t# normalize unicode characters. needed to convert some german characters to ascii\n",
    "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\t\tline = line.decode('UTF-8')\n",
    "\t\t\t# tokenize on white space\n",
    "\t\t\tline = line.split()\n",
    "\t\t\t# remove punctuation from each token\n",
    "\t\t\tline = [word.translate(table) for word in line]\n",
    "\t\t\t# remove non-printable chars form each token\n",
    "\t\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t\t# remove tokens with numbers in them\n",
    "\t\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t\t# store as string\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = '../data/deu.txt'\n",
    "doc = load_doc(filename)\n",
    "# split into english-german pairs\n",
    "pairs = to_pairs(doc)\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "#use the first 18k sentences to train, validate and test the model\n",
    "clean_pairs = clean_pairs[0:18000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "[['You could lead' 'Sie konnten die Fuhrung ubernehmen']\n",
      " ['Im in danger' 'Ich bin in Gefahr']\n",
      " ['The partys over' 'Die Fete ist beendet']\n",
      " ['Can you forgive me' 'Kannst du mir verzeihen']\n",
      " ['Hey I know you' 'He dich kenne ich doch']\n",
      " ['We know this' 'Wir wissen das']\n",
      " ['What was he up to' 'Was hatte er vor']\n",
      " ['Nothing happened' 'Nix passiert']\n",
      " ['Im not certain' 'Ich bin mir nicht sicher']\n",
      " ['He is very tall' 'Er ist sehr gro']]\n",
      "(16000, 2)\n",
      "[['I have a big house' 'Ich habe ein groes Haus']\n",
      " ['Lets get off here' 'Lasst uns hier aussteigen']\n",
      " ['Thats so annoying' 'Das ist so nervig']\n",
      " ['Tom was impolite' 'Tom war unhoflich']\n",
      " ['The book is white' 'Das Buch ist wei']\n",
      " ['Look what I did' 'Schau mal was ich gemacht habe']\n",
      " ['Give Tom a kiss' 'Gib dem Tom einen Kuss']\n",
      " ['Dont let me down' 'Lassen Sie mich nicht im Stich']\n",
      " ['It may seem odd' 'Es mag eigenartig erscheinen']\n",
      " ['Youre being mean' 'Du bist gemein']]\n",
      "(1000, 2)\n",
      "[['Did Tom need help' 'Hat Tom Hilfe gebraucht']\n",
      " ['Tom bought a dog' 'Tom hat sich einen Hund gekauft']\n",
      " ['She dumped me' 'Sie hat mir den Laufpass gegeben']\n",
      " ['I looked for a job' 'Ich suchte nach einer Anstellung']\n",
      " ['I loved you' 'Ich liebte dich']\n",
      " ['Tom offended Mary' 'Tom beleidigte Mary']\n",
      " ['Try this sauce' 'Probieren Sie diese Soe']\n",
      " ['I ordered pizza' 'Ich habe Pizza bestellt']\n",
      " ['Do not do that' 'Tu das nicht']\n",
      " ['Dont be too sure' 'Sei dir nicht zu sicher']]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(clean_pairs)\n",
    "train_clean = clean_pairs[0:16000]\n",
    "val_clean = clean_pairs[16000:17000]\n",
    "test_clean = clean_pairs[17000:]\n",
    "print(\"Validation data shape\",val_clean.shape)\n",
    "print(\"Validation data sentences\",val_clean[0:10])\n",
    "print(\"Training data shape\",train_clean.shape)\n",
    "print(\"Validation data sentences\",train_clean[0:10])\n",
    "print(\"Test data shape\",test_clean.shape)\n",
    "print(\"Test data sentences\",test_clean[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I stored the english senetence from the pair to train.en and german senetence to train.de.\n",
    "#Similarly for the validation and test data\n",
    "#I did this because I couldn't figure out how to use a dataset in torchtext to load the sentences. So I used to Multi30k structure.\n",
    "#Something to work on in the future.\n",
    "eng_file = \"./.data/multi30k/train.en\"\n",
    "ge_file = \"./.data/multi30k/train.de\"\n",
    "en_pt = open(eng_file,\"w\")\n",
    "ge_pt = open(ge_file,\"w\")\n",
    "\n",
    "for p in train_clean:\n",
    "    en_pt.write(p[0]+\"\\n\")\n",
    "    ge_pt.write(p[1]+\"\\n\")\n",
    "    \n",
    "en_pt.close()\n",
    "ge_pt.close()\n",
    "\n",
    "eng_file = \"./.data/multi30k/val.en\"\n",
    "ge_file = \"./.data/multi30k/val.de\"\n",
    "en_pt = open(eng_file,\"w\")\n",
    "ge_pt = open(ge_file,\"w\")\n",
    "\n",
    "for p in val_clean:\n",
    "    en_pt.write(p[0]+\"\\n\")\n",
    "    ge_pt.write(p[1]+\"\\n\")\n",
    "    \n",
    "en_pt.close()\n",
    "ge_pt.close()\n",
    "\n",
    "eng_file = \"./.data/multi30k/test2016.en\"\n",
    "ge_file = \"./.data/multi30k/test2016.de\"\n",
    "en_pt = open(eng_file,\"w\")\n",
    "ge_pt = open(ge_file,\"w\")\n",
    "\n",
    "for p in test_clean:\n",
    "    en_pt.write(p[0]+\"\\n\")\n",
    "    ge_pt.write(p[1]+\"\\n\")\n",
    "    \n",
    "en_pt.close()\n",
    "ge_pt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHIT\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#lower argument converts all strings to lower case\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHIT\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#load in training, validation and test data\n",
    "train_data,valid_data,test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 16000\n",
      "Number of validation examples: 1000\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['lassen', 'wir', 'einen', 'drachen', 'steigen'], 'trg': ['lets', 'fly', 'a', 'kite']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[39]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the vocabulary with a minimum threshold of 2 for word count\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 2928\n",
      "Unique tokens in target (en) vocabulary: 2175\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHIT\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        #embedded = [sentence len, batch size, emb dim]\n",
    "        #outputs (the top-layer hidden state for each time-step), hidden (the final hidden state for each layer, \n",
    "        #h_T, stacked on top of each other) and cell (the final cell state for each layer, c_T, \n",
    "        #stacked on top of each other).\n",
    "        #n_directions=1 because the LSTM is not bidirectional\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        #outputs = [sentence len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim,)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        #self.softmax = nn.LogSoftmax(dim=0)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        #output of cell state and hidden state of encoder go to the decoder\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        \n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        #print(prediction.shape)\n",
    "        #prediction = self.softmax(prediction)\n",
    "        #print(prediction.shape)\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            #print(top1.shape)\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(2928, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2175, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=2175, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,778,559 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(iterator)):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #applying gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(tqdm(iterator)):\n",
    "\n",
    "            src = batch.src\n",
    "            #print(\"src1\",src.shape)\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            #print(\"output b4\",output.shape)\n",
    "            #print(output[0,0,0])\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    #tokenize german senetece\n",
    "    tokens = tokenize_de(sentence)\n",
    "    #insert sos token at start of sentence\n",
    "    tokens.insert(0, SRC.init_token)\n",
    "    tokens.append(SRC.eos_token)\n",
    "    \n",
    "    #convert words to numbers according to the vobaulary\n",
    "    text_to_indices = [SRC.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(sentence_tensor)\n",
    "    \n",
    "    #output begins with sos, so append it to the output\n",
    "    outputs = [TRG.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    #while predicting, the previous output is the input to the next step\n",
    "    for _ in range(50):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "        \n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == TRG.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "    \n",
    "    #convert the numbers to words using vocabulary\n",
    "    translated_sentence = [TRG.vocab.itos[idx] for idx in outputs]\n",
    "    print(translated_sentence[1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 48.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.061 | Test PPL:   7.854 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/model-v4.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:08<00:00, 28.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 111.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 're', 'a', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                 | 3/250 [00:00<00:08, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 9s\n",
      "\tTrain Loss: 4.296 | Train PPL:  73.408\n",
      "\t Val. Loss: 3.760 |  Val. PPL:  42.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:13<00:00, 18.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.60it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'need', 'a', '<eos>']\n",
      "Epoch: 02 | Time: 0m 14s\n",
      "\tTrain Loss: 3.509 | Train PPL:  33.404\n",
      "\t Val. Loss: 3.404 |  Val. PPL:  30.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:49<00:00,  5.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 've', 'a', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 50s\n",
      "\tTrain Loss: 3.059 | Train PPL:  21.316\n",
      "\t Val. Loss: 3.010 |  Val. PPL:  20.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:49<00:00,  5.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.28it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 've', 'a', 'a', '<eos>']\n",
      "Epoch: 04 | Time: 0m 50s\n",
      "\tTrain Loss: 2.716 | Train PPL:  15.118\n",
      "\t Val. Loss: 2.830 |  Val. PPL:  16.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:51<00:00,  4.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'a', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 52s\n",
      "\tTrain Loss: 2.440 | Train PPL:  11.477\n",
      "\t Val. Loss: 2.650 |  Val. PPL:  14.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:56<00:00,  4.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'met', 'a', 'car', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 57s\n",
      "\tTrain Loss: 2.193 | Train PPL:   8.966\n",
      "\t Val. Loss: 2.590 |  Val. PPL:  13.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 've', 'a', 'a', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 54s\n",
      "\tTrain Loss: 1.979 | Train PPL:   7.236\n",
      "\t Val. Loss: 2.405 |  Val. PPL:  11.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:52<00:00,  4.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'met', 'a', 'fault', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 53s\n",
      "\tTrain Loss: 1.791 | Train PPL:   5.994\n",
      "\t Val. Loss: 2.308 |  Val. PPL:  10.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:51<00:00,  4.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'met', 'one', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 52s\n",
      "\tTrain Loss: 1.614 | Train PPL:   5.023\n",
      "\t Val. Loss: 2.227 |  Val. PPL:   9.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 54s\n",
      "\tTrain Loss: 1.454 | Train PPL:   4.281\n",
      "\t Val. Loss: 2.182 |  Val. PPL:   8.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 54s\n",
      "\tTrain Loss: 1.315 | Train PPL:   3.726\n",
      "\t Val. Loss: 2.136 |  Val. PPL:   8.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'a', 'job', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 54s\n",
      "\tTrain Loss: 1.181 | Train PPL:   3.258\n",
      "\t Val. Loss: 2.127 |  Val. PPL:   8.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:52<00:00,  4.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.31it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 13 | Time: 0m 53s\n",
      "\tTrain Loss: 1.061 | Train PPL:   2.890\n",
      "\t Val. Loss: 2.040 |  Val. PPL:   7.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:50<00:00,  4.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.15it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 14 | Time: 0m 51s\n",
      "\tTrain Loss: 0.956 | Train PPL:   2.602\n",
      "\t Val. Loss: 2.046 |  Val. PPL:   7.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 54s\n",
      "\tTrain Loss: 0.861 | Train PPL:   2.366\n",
      "\t Val. Loss: 2.014 |  Val. PPL:   7.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 54s\n",
      "\tTrain Loss: 0.773 | Train PPL:   2.167\n",
      "\t Val. Loss: 1.978 |  Val. PPL:   7.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.03it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 17 | Time: 0m 54s\n",
      "\tTrain Loss: 0.705 | Train PPL:   2.024\n",
      "\t Val. Loss: 2.018 |  Val. PPL:   7.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.13it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 18 | Time: 0m 54s\n",
      "\tTrain Loss: 0.637 | Train PPL:   1.891\n",
      "\t Val. Loss: 2.023 |  Val. PPL:   7.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.59it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 19 | Time: 0m 55s\n",
      "\tTrain Loss: 0.583 | Train PPL:   1.791\n",
      "\t Val. Loss: 1.997 |  Val. PPL:   7.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.94it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 20 | Time: 0m 54s\n",
      "\tTrain Loss: 0.536 | Train PPL:   1.709\n",
      "\t Val. Loss: 1.993 |  Val. PPL:   7.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.85it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 21 | Time: 0m 54s\n",
      "\tTrain Loss: 0.490 | Train PPL:   1.633\n",
      "\t Val. Loss: 2.015 |  Val. PPL:   7.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.87it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 5.0000e-04.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 22 | Time: 0m 55s\n",
      "\tTrain Loss: 0.454 | Train PPL:   1.575\n",
      "\t Val. Loss: 2.025 |  Val. PPL:   7.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.23it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 23 | Time: 0m 54s\n",
      "\tTrain Loss: 0.362 | Train PPL:   1.437\n",
      "\t Val. Loss: 2.008 |  Val. PPL:   7.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.04it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 24 | Time: 0m 54s\n",
      "\tTrain Loss: 0.317 | Train PPL:   1.373\n",
      "\t Val. Loss: 2.041 |  Val. PPL:   7.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.47it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 25 | Time: 0m 54s\n",
      "\tTrain Loss: 0.300 | Train PPL:   1.350\n",
      "\t Val. Loss: 2.047 |  Val. PPL:   7.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.57it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 26 | Time: 0m 54s\n",
      "\tTrain Loss: 0.291 | Train PPL:   1.337\n",
      "\t Val. Loss: 2.063 |  Val. PPL:   7.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.63it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 27 | Time: 0m 54s\n",
      "\tTrain Loss: 0.278 | Train PPL:   1.320\n",
      "\t Val. Loss: 2.080 |  Val. PPL:   8.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.16it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-04.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 28 | Time: 0m 54s\n",
      "\tTrain Loss: 0.266 | Train PPL:   1.304\n",
      "\t Val. Loss: 2.085 |  Val. PPL:   8.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.57it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 29 | Time: 0m 54s\n",
      "\tTrain Loss: 0.230 | Train PPL:   1.259\n",
      "\t Val. Loss: 2.093 |  Val. PPL:   8.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.66it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 30 | Time: 0m 55s\n",
      "\tTrain Loss: 0.223 | Train PPL:   1.250\n",
      "\t Val. Loss: 2.107 |  Val. PPL:   8.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.03it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 31 | Time: 0m 54s\n",
      "\tTrain Loss: 0.216 | Train PPL:   1.241\n",
      "\t Val. Loss: 2.106 |  Val. PPL:   8.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.94it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 32 | Time: 0m 54s\n",
      "\tTrain Loss: 0.213 | Train PPL:   1.237\n",
      "\t Val. Loss: 2.126 |  Val. PPL:   8.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.05it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 33 | Time: 0m 54s\n",
      "\tTrain Loss: 0.204 | Train PPL:   1.226\n",
      "\t Val. Loss: 2.144 |  Val. PPL:   8.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.01it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    34: reducing learning rate of group 0 to 1.2500e-04.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 34 | Time: 0m 54s\n",
      "\tTrain Loss: 0.204 | Train PPL:   1.227\n",
      "\t Val. Loss: 2.148 |  Val. PPL:   8.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.69it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 35 | Time: 0m 54s\n",
      "\tTrain Loss: 0.186 | Train PPL:   1.205\n",
      "\t Val. Loss: 2.145 |  Val. PPL:   8.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.87it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 36 | Time: 0m 54s\n",
      "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
      "\t Val. Loss: 2.164 |  Val. PPL:   8.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.69it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 37 | Time: 0m 54s\n",
      "\tTrain Loss: 0.178 | Train PPL:   1.195\n",
      "\t Val. Loss: 2.173 |  Val. PPL:   8.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.81it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 38 | Time: 0m 54s\n",
      "\tTrain Loss: 0.178 | Train PPL:   1.195\n",
      "\t Val. Loss: 2.184 |  Val. PPL:   8.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:57<00:00,  4.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.83it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 39 | Time: 0m 58s\n",
      "\tTrain Loss: 0.176 | Train PPL:   1.192\n",
      "\t Val. Loss: 2.175 |  Val. PPL:   8.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.99it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    40: reducing learning rate of group 0 to 6.2500e-05.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 40 | Time: 0m 54s\n",
      "\tTrain Loss: 0.173 | Train PPL:   1.188\n",
      "\t Val. Loss: 2.170 |  Val. PPL:   8.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.96it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 41 | Time: 0m 55s\n",
      "\tTrain Loss: 0.162 | Train PPL:   1.176\n",
      "\t Val. Loss: 2.170 |  Val. PPL:   8.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.94it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 42 | Time: 0m 54s\n",
      "\tTrain Loss: 0.163 | Train PPL:   1.177\n",
      "\t Val. Loss: 2.164 |  Val. PPL:   8.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.07it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 43 | Time: 0m 54s\n",
      "\tTrain Loss: 0.163 | Train PPL:   1.177\n",
      "\t Val. Loss: 2.177 |  Val. PPL:   8.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.43it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 44 | Time: 0m 55s\n",
      "\tTrain Loss: 0.159 | Train PPL:   1.172\n",
      "\t Val. Loss: 2.170 |  Val. PPL:   8.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.03it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 45 | Time: 0m 55s\n",
      "\tTrain Loss: 0.159 | Train PPL:   1.172\n",
      "\t Val. Loss: 2.174 |  Val. PPL:   8.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.05it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    46: reducing learning rate of group 0 to 3.1250e-05.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 46 | Time: 0m 54s\n",
      "\tTrain Loss: 0.159 | Train PPL:   1.173\n",
      "\t Val. Loss: 2.180 |  Val. PPL:   8.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.33it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 47 | Time: 0m 54s\n",
      "\tTrain Loss: 0.156 | Train PPL:   1.169\n",
      "\t Val. Loss: 2.176 |  Val. PPL:   8.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.51it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 48 | Time: 0m 54s\n",
      "\tTrain Loss: 0.152 | Train PPL:   1.165\n",
      "\t Val. Loss: 2.182 |  Val. PPL:   8.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.58it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 49 | Time: 0m 55s\n",
      "\tTrain Loss: 0.155 | Train PPL:   1.167\n",
      "\t Val. Loss: 2.192 |  Val. PPL:   8.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:56<00:00,  4.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 27.32it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 50 | Time: 0m 57s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.167\n",
      "\t Val. Loss: 2.181 |  Val. PPL:   8.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 29.57it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 51 | Time: 0m 37s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.166\n",
      "\t Val. Loss: 2.186 |  Val. PPL:   8.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.99it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    52: reducing learning rate of group 0 to 1.5625e-05.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 52 | Time: 0m 37s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.167\n",
      "\t Val. Loss: 2.191 |  Val. PPL:   8.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 29.93it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 53 | Time: 0m 37s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.162\n",
      "\t Val. Loss: 2.192 |  Val. PPL:   8.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.51it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:49,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 54 | Time: 0m 37s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.161\n",
      "\t Val. Loss: 2.189 |  Val. PPL:   8.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.02it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 55 | Time: 0m 37s\n",
      "\tTrain Loss: 0.151 | Train PPL:   1.163\n",
      "\t Val. Loss: 2.193 |  Val. PPL:   8.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:38<00:00,  6.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 35.30it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 56 | Time: 0m 38s\n",
      "\tTrain Loss: 0.148 | Train PPL:   1.160\n",
      "\t Val. Loss: 2.191 |  Val. PPL:   8.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  8.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 42.87it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:37,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 57 | Time: 0m 28s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.162\n",
      "\t Val. Loss: 2.188 |  Val. PPL:   8.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 46.82it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:41,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    58: reducing learning rate of group 0 to 7.8125e-06.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 58 | Time: 0m 27s\n",
      "\tTrain Loss: 0.147 | Train PPL:   1.159\n",
      "\t Val. Loss: 2.196 |  Val. PPL:   8.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 44.73it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 59 | Time: 0m 27s\n",
      "\tTrain Loss: 0.151 | Train PPL:   1.163\n",
      "\t Val. Loss: 2.190 |  Val. PPL:   8.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 41.86it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:43,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 60 | Time: 0m 27s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.161\n",
      "\t Val. Loss: 2.189 |  Val. PPL:   8.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 42.55it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 61 | Time: 0m 27s\n",
      "\tTrain Loss: 0.148 | Train PPL:   1.159\n",
      "\t Val. Loss: 2.190 |  Val. PPL:   8.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:34<00:00,  7.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 42.95it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 62 | Time: 0m 34s\n",
      "\tTrain Loss: 0.147 | Train PPL:   1.159\n",
      "\t Val. Loss: 2.189 |  Val. PPL:   8.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.52it/s]\n",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 63 | Time: 0m 37s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.161\n",
      "\t Val. Loss: 2.189 |  Val. PPL:   8.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 29.69it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:41,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    64: reducing learning rate of group 0 to 3.9063e-06.\n",
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 64 | Time: 0m 37s\n",
      "\tTrain Loss: 0.147 | Train PPL:   1.158\n",
      "\t Val. Loss: 2.187 |  Val. PPL:   8.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 40.29it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:40,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 65 | Time: 0m 27s\n",
      "\tTrain Loss: 0.147 | Train PPL:   1.158\n",
      "\t Val. Loss: 2.188 |  Val. PPL:   8.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 42.13it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:39,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 66 | Time: 0m 27s\n",
      "\tTrain Loss: 0.146 | Train PPL:   1.158\n",
      "\t Val. Loss: 2.187 |  Val. PPL:   8.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:27<00:00,  9.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 45.37it/s]\n",
      "  0%|▎                                                                                 | 1/250 [00:00<00:38,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'found', 'one', '<eos>']\n",
      "Epoch: 67 | Time: 0m 27s\n",
      "\tTrain Loss: 0.148 | Train PPL:   1.160\n",
      "\t Val. Loss: 2.188 |  Val. PPL:   8.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████▉                             | 159/250 [00:17<00:10,  9.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8c1ddd86c64b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-8c27c27d6fea>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    scheduler.step(valid_loss)\n",
    "    evaluate_sentence(\"Wir haben eine gefunden\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/model-v4.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 26.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.022 | Test PPL:   7.551 |\n",
      "478\n",
      "GT what a surprise\n",
      "TT Was fur eine Uberraschung\n",
      "['what', 'a', 'shame', '<eos>']\n",
      "710\n",
      "GT i looked for a job\n",
      "TT Ich suchte nach einer Arbeit\n",
      "['i', 'slapped', 'a', 'day', '<eos>']\n",
      "51\n",
      "GT hes a man now\n",
      "TT Er ist jetzt ein Mann\n",
      "['he', 's', 'already', 'a', 'age', '<eos>']\n",
      "533\n",
      "GT tom whistled\n",
      "TT Tom pfiff\n",
      "['tom', 'is', '<eos>']\n",
      "428\n",
      "GT is tom married\n",
      "TT Ist Tom verheiratet\n",
      "['is', 'tom', 'married', '<eos>']\n",
      "957\n",
      "GT the answer is\n",
      "TT Die Antwort lautet zweiundvierzig\n",
      "['the', '<unk>', 'is', 'melting', '<eos>']\n",
      "957\n",
      "GT the answer is\n",
      "TT Die Antwort lautet zweiundvierzig\n",
      "['the', '<unk>', 'is', 'melting', '<eos>']\n",
      "101\n",
      "GT pass me the salt\n",
      "TT Gib mir bitte das Salz ruber\n",
      "['please', 'give', 'me', 'a', '<eos>']\n",
      "672\n",
      "GT youre in trouble\n",
      "TT Du steckst in Schwierigkeiten\n",
      "['you', 're', 'in', 'trouble', '<eos>']\n",
      "45\n",
      "GT this book is small\n",
      "TT Das Buch ist dunn\n",
      "['the', 'book', 'is', 'cold', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/model-v4.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n",
    "\n",
    "#random.choice(test_clean)\n",
    "test_file = open(\"./.data/multi30k/test2016.de\")\n",
    "test_sentences = []\n",
    "for sentence in test_file:\n",
    "    sentence = sentence.strip(\"\\n\")\n",
    "    test_sentences.append(sentence)\n",
    "    \n",
    "test_file.close()\n",
    "test_file = open(\"./.data/multi30k/test2016.en\")\n",
    "ground_truth = []\n",
    "for sentence in test_file:\n",
    "    sentence = sentence.strip(\"\\n\")\n",
    "    ground_truth.append(sentence)\n",
    "test_file.close()\n",
    "#print(test_sentences[0:10])\n",
    "i=0\n",
    "while i<10:\n",
    "    pair_choice = random.randint(0, 1000)\n",
    "    print(pair_choice)\n",
    "    ground_truth_sen = ground_truth[pair_choice]\n",
    "    ground_truth_sen = ground_truth_sen.lower()\n",
    "    to_test = test_sentences[pair_choice]\n",
    "    print(\"GT\",ground_truth_sen)\n",
    "    print(\"TT\",to_test)\n",
    "    evaluate_sentence(to_test.lower())\n",
    "    #print(ground_truth)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
